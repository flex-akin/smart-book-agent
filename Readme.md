
# 📚 Smart Book Discovery Agent – AnchorBrowser Take-Home Task

This project is a TypeScript-based automation agent that scrapes book data from [BookDP.com.au](https://bookdp.com.au), enriches it using OpenAI GPT-4, performs cost analysis, and sends the result to a productivity tool like Google Sheets using Make.com.

---

## 🚀 Project Overview

The agent performs the following tasks:

1. **Web Scraping**
   - Accepts a search theme as input (e.g., "climate change").
   - Uses Puppeteer to search BookDP.com.au.
   - Scrapes the first two pages of results for each theme.

2. **Data Extraction**
   - Title
   - Author (if available)
   - Current and Original Price
   - Discount amount and percentage
   - Book Description
   - Product URL
   - Publisher
   - Metadata (e.g., ISBN, publication date)

3. **AI Enrichment**
   - Summarizes the book description using GPT-4.
   - Assigns a thematic relevance score (0–100).

4. **Cost Analysis**
   - Calculates discount percentage and absolute discount.
   - Calculates a **value score**: `valueScore = relevanceScore / currentPrice`.

5. **API Access**
   - POST `/scrape` – Start a scraping job
   - GET `/status/:jobId` – Check job status
   - GET `/results/:jobId` – Get enriched data

6. **Make.com Integration**
   - Enriched data is POSTed to a configured Make.com webhook for automation into tools like Google Sheets.

---

## 🧱 Architecture & Approach

- **Express + TypeScript**: API server
- **Tsoa**: Generates Swagger docs automatically
- **Puppeteer**: Scrapes BookDP.com.au
- **OpenAI GPT-4**: Text summarization and scoring
- **PostgreSQL**: Persists scraped job results
- **Sequelize**: ORM for managing database models
- **Make.com**: External integration platform
- **Docker**: Containerized deployment

---

## 💻 Running Locally

### 1. Clone and Install
```bash
git clone https://github.com/flex-akin/smart-book-agent
cd smart-book-agent
npm install
```

### 2. Environment Variables

Create a `.env` file in the root:

```env
PORT=4040
DB_USERNAME=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=localhost
DB_NAME=smartbooks
DB_PORT=5432
OPENAI_API_KEY=your_openai_api_key
```

### 3. Run the Project

Use:
```bash
yarn dev
```
or
```bash
yarn start
```

---

## 🐳 Docker Deployment

Build and run the container:
```bash
docker-compose up --build
```

Make sure your `.env` file is correctly set before running this.

---

## 🔌 API Endpoints

| Method | Route               | Description                          |
|--------|---------------------|--------------------------------------|
| POST   | `/scrape`           | Start a new scrape session           |
| GET    | `/status/:jobId`    | Get the scrape job status            |
| GET    | `/results/:jobId`   | Retrieve the enriched book data      |

### 🔍 Swagger Docs

Access detailed API schema at:  
👉 **[http://localhost:4040/api-docs](http://localhost:4040/api-docs)**

---

## 🔗 Make.com Integration

1. In your Make.com dashboard, create a **Scenario** with a **Webhook** trigger.
2. Copy the webhook URL and save it in your backend configuration (optional `.env` or code file).
3. When a job completes, the enriched book data will be POSTed to the webhook in JSON format.

### 📸 Screenshot


---

## 🧩 Assumptions & Limitations

- BookDP.com.au’s HTML structure is assumed to be stable.
- Book entries may have missing fields (e.g., no author).
- Relevance scoring is subjective and generated by GPT-4.
- Value score assumes numeric parsing from currency strings.
- Rate limits for OpenAI or scraping are not enforced yet.
- Make.com webhook errors are not retried (basic integration).

---

## 📁 Project Scripts

Check `package.json` for all available commands:
```json
  "scripts": {
    "test": "jest",
    "predev": "npm run swagger",
    "prebuild": "npm run swagger",
    "build": "tsc --build",
    "start": "node ./dist/index.js",
    "start:dev": "concurrently \"nodemon\" \"nodemon -x tsoa spec\"",
    "swagger": "tsoa spec",
    "format": "prettier --ignore-path .gitignore --write \"**/*.+(js|ts|json)\""
  },
```

**Made with ❤️ by [Your Name]**  
_This project was built as part of the AnchorBrowser technical task._
